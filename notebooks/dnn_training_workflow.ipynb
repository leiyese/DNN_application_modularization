{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da8ac68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (optional, if you want to save outputs to Drive)\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# Set your project path in Google Drive (adjust as needed)\n",
    "# PROJECT_DRIVE_PATH = '/content/drive/MyDrive/your_colab_projects/dynamic_dnn_trainer'\n",
    "# If not using Drive, you can clone directly into Colab's temporary storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12ff6f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this cell if you haven't cloned the repo in your Colab environment yet\n",
    "# or if you want to pull the latest changes.\n",
    "\n",
    "# !git clone <https://github.com/leiyese/dynamic_dnn_trainer> dynamic_dnn_trainer_colab\n",
    "# %cd dynamic_dnn_trainer_colab\n",
    "\n",
    "# If you mounted Drive and your project is there:\n",
    "# %cd $PROJECT_DRIVE_PATH\n",
    "# !git pull # To get latest changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e810b2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/leiye/dev/jensens/6_AI/excercises/6-CNN/dynamic_dnn_trainer/notebooks\n",
      "System path: ['/Users/leiye/dev/jensens/6_AI/excercises/6-CNN/dynamic_dnn_trainer/notebooks', '/Users/leiye/anaconda3/lib/python312.zip', '/Users/leiye/anaconda3/lib/python3.12', '/Users/leiye/anaconda3/lib/python3.12/lib-dynload', '', '/Users/leiye/anaconda3/lib/python3.12/site-packages', '/Users/leiye/anaconda3/lib/python3.12/site-packages/aeosa', '/Users/leiye/anaconda3/lib/python3.12/site-packages/setuptools/_vendor', 'src']\n"
     ]
    }
   ],
   "source": [
    "# Install requirements\n",
    "# Make sure your requirements.txt is up-to-date in your repo\n",
    "# !pip install -q -r requirements.txt\n",
    "\n",
    "# Add src to Python path to import our modules\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Adjust the path depending on where your notebook is relative to the 'src' directory\n",
    "# If notebook is in 'dynamic_dnn_trainer/notebooks/' and src is 'dynamic_dnn_trainer/src/'\n",
    "# And your current working directory is 'dynamic_dnn_trainer_colab' (or your project root)\n",
    "if 'src' not in sys.path:\n",
    "    sys.path.append('src')\n",
    "# Or, more robustly if you know the project root:\n",
    "# project_root = os.path.abspath(os.path.join(os.getcwd())) # Assumes CWD is project root\n",
    "# src_path = os.path.join(project_root, 'src')\n",
    "# if src_path not in sys.path:\n",
    "#    sys.path.append(src_path)\n",
    "\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(f\"System path: {sys.path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62b892b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Import from our custom modules in src\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_ingestion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m loader\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meda\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m exploratory_analysis \u001b[38;5;28;01mas\u001b[39;00m eda\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import from our custom modules in src\n",
    "from src import config\n",
    "from src.data_ingestion import loader\n",
    "from src.eda import exploratory_analysis as eda\n",
    "from src.preprocessing import transformers\n",
    "from src.utils import helpers\n",
    "\n",
    "print(\"Successfully imported all modules.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c834b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might want to define specific output paths for notebook experiments\n",
    "# For now, we'll use the paths from config.py\n",
    "NOTEBOOK_PLOTS_DIR = config.PLOTS_OUTPUT_DIR / \"notebook_eda\"\n",
    "NOTEBOOK_PROCESSED_DATA_DIR = config.PROCESSED_DATA_DIR / \"notebook_processed\"\n",
    "NOTEBOOK_PREPROCESSOR_PATH = NOTEBOOK_PROCESSED_DATA_DIR / \"notebook_preprocessor.pkl\"\n",
    "NOTEBOOK_TARGET_ENCODER_PATH = NOTEBOOK_PROCESSED_DATA_DIR / \"notebook_target_encoder.pkl\"\n",
    "\n",
    "# Ensure these directories exist\n",
    "NOTEBOOK_PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "NOTEBOOK_PROCESSED_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Notebook plots will be saved to: {NOTEBOOK_PLOTS_DIR}\")\n",
    "print(f\"Notebook processed data artifacts will be saved to: {NOTEBOOK_PROCESSED_DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5a7f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- 1. Loading Raw Data ---\")\n",
    "if config.RAW_DATA_FILE.exists():\n",
    "    raw_df = loader.load_csv_data(file_path=config.RAW_DATA_FILE)\n",
    "    print(\"\\nRaw data loaded successfully. First 5 rows:\")\n",
    "    print(raw_df.head())\n",
    "else:\n",
    "    print(f\"ERROR: Raw data file not found at {config.RAW_DATA_FILE}\")\n",
    "    raw_df = None # Or raise an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce7734d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if raw_df is not None:\n",
    "    print(\"\\n--- 2. Performing Exploratory Data Analysis (EDA) ---\")\n",
    "    _ = eda.generate_descriptive_stats(raw_df)\n",
    "    _ = eda.get_null_counts(raw_df)\n",
    "    eda.plot_histograms_for_numerical_features(\n",
    "        df=raw_df,\n",
    "        numerical_features=config.NUMERICAL_FEATURES,\n",
    "        save_dir=NOTEBOOK_PLOTS_DIR\n",
    "    )\n",
    "    eda.plot_correlation_matrix(\n",
    "        df=raw_df,\n",
    "        numerical_features=config.NUMERICAL_FEATURES,\n",
    "        save_path=NOTEBOOK_PLOTS_DIR / \"correlation_matrix_notebook.png\"\n",
    "    )\n",
    "    print(\"\\nEDA plots saved. Check the output directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a249a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if raw_df is not None:\n",
    "    print(\"\\n--- 3. Splitting Data ---\")\n",
    "    X_train_raw, X_test_raw, y_train_raw, y_test_raw = transformers.split_data(\n",
    "        df=raw_df,\n",
    "        target_column=config.TARGET_COLUMN,\n",
    "        test_size=config.TEST_SPLIT_SIZE,\n",
    "        random_state=config.RANDOM_STATE,\n",
    "        stratify_col=raw_df[config.TARGET_COLUMN]\n",
    "    )\n",
    "    print(\"Data splitting complete.\")\n",
    "    print(f\"X_train_raw shape: {X_train_raw.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267d387b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X_train_raw' in locals() and X_train_raw is not None: # Check if previous step ran\n",
    "    print(\"\\n--- 4. Preprocessing Features ---\")\n",
    "    X_train_proc, X_test_proc, fitted_preprocessor = transformers.preprocess_features(\n",
    "        X_train=X_train_raw.copy(),\n",
    "        X_test=X_test_raw.copy(),\n",
    "        numerical_features=config.NUMERICAL_FEATURES,\n",
    "        categorical_features=config.CATEGORICAL_FEATURES,\n",
    "        preprocessor_save_path=NOTEBOOK_PREPROCESSOR_PATH,\n",
    "        fit_preprocessor=True # Fit a new one for this notebook run\n",
    "    )\n",
    "    print(\"Feature preprocessing complete.\")\n",
    "    print(f\"X_train_proc head (first 5 rows of processed data):\\n{X_train_proc.head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01cb43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'y_train_raw' in locals() and y_train_raw is not None: # Check if previous step ran\n",
    "    print(\"\\n--- 5. Encoding Target Variable ---\")\n",
    "    y_train_enc, y_test_enc, fitted_target_encoder = transformers.encode_target(\n",
    "        y_train=y_train_raw.copy(),\n",
    "        y_test=y_test_raw.copy(),\n",
    "        encoder_save_path=NOTEBOOK_TARGET_ENCODER_PATH,\n",
    "        fit_encoder=True # Fit a new one for this notebook run\n",
    "    )\n",
    "    print(\"Target encoding complete.\")\n",
    "    print(f\"y_train_enc head:\\n{y_train_enc.head()}\")\n",
    "    print(f\"Target classes: {fitted_target_encoder.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8594c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X_train_proc' in locals() and X_train_proc is not None:\n",
    "    print(\"\\n--- Processed Data Overview ---\")\n",
    "    print(\"X_train_proc (processed features) head:\")\n",
    "    display(X_train_proc.head()) # Use display for better DataFrame rendering in notebooks\n",
    "    print(\"\\ny_train_enc (encoded target) head:\")\n",
    "    display(y_train_enc.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
